{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHere use self developed covolutional neural\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dg\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "'''\n",
    "Here use self developed covolutional neural\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here data is a PyTorch tensor\n",
    "def imshow(data):\n",
    "    img = data / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(npimg.reshape([28,28]), cmap = 'gray')\n",
    "    plt.show()\n",
    "\n",
    "def label2onehot(labels):\n",
    "    b_size = len(labels)\n",
    "    ret = np.zeros([b_size, 10, 1])\n",
    "    for i, label in enumerate(labels):\n",
    "        ret[i][label] = 1\n",
    "    return ret\n",
    "def calc_acc(out, label):\n",
    "    out_tsr   = out.reshape(out.shape[:2])\n",
    "    label_tsr = label.reshape(label.shape[:2])\n",
    "    argmax_out = np.argmax(out_tsr, 1)\n",
    "    argmax_label = np.argmax(label_tsr, 1)\n",
    "    eq = (argmax_out == argmax_label)\n",
    "    num_corr = np.count_nonzero(eq)\n",
    "    return num_corr / len(out_tsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define batch size and data loaders, including train data and test data loaders\n",
    "batch_size = 25\n",
    "num_labels = 10\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root = './data', train = True,\n",
    "                                      download = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size,\n",
    "                                          shuffle = True, num_workers = 2)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train = False,\n",
    "                                     download=True, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size,\n",
    "                                         shuffle = False, num_workers = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data from PyTorch data loaders:\n",
      "x_data[0].type: <class 'torch.Tensor'>\n",
      "torch.Size([1, 28, 28])\n",
      "y_data[0].type: <class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: tensor(2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# first take a look at some of the test pictures\n",
    "train_iter = iter(trainloader)\n",
    "x_data, y_data = train_iter.next()\n",
    "print('data from PyTorch data loaders:')\n",
    "print('x_data[0].type:', type(x_data[0]))\n",
    "print(x_data[0].shape)\n",
    "print('y_data[0].type:', type(y_data[0]))\n",
    "print(y_data[0].shape)\n",
    "for i in range(2):\n",
    "    imshow(x_data[i])\n",
    "    print('label:', y_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def one_conv_layer(self):\n",
    "        print('Creating one conv layer CNN...')\n",
    "        x_entry = x_data.numpy().reshape([batch_size, 28, 28, 1])\n",
    "        y_entry = label2onehot(y_data).reshape([batch_size, num_labels, 1])\n",
    "        print('Input image shape:', x_entry.shape)\n",
    "        print('Y label shape:', y_entry.shape)\n",
    "        print()\n",
    "        img_in = dg.identity(x_entry)\n",
    "        y_label = dg.identity(y_entry)\n",
    "        conv = dg.cnn.conv(img_in, 5, 6)\n",
    "        print('added conv layer with filter size: {}, num_filter: {}, stride: {}, padding: {}, out shape: {}'\\\n",
    "              .format(conv.op.filter_size, conv.op.num_filter, conv.op.stride, conv.op.padding, conv.shape()))\n",
    "        relu = dg.relu(conv)\n",
    "        print('added relu, shape:', relu.shape())\n",
    "        pool = dg.cnn.max_pool(relu, 3, stride = 3)\n",
    "        print('added pool with filter size: {}, stride: {}, padding: {}, out shape: {}'\\\n",
    "              .format(pool.op.filter_size, pool.op.stride, pool.op.padding, pool.shape()))\n",
    "        fl = dg.reshape(pool, (batch_size, 384, 1))\n",
    "        print('added reshaped layer, the new shape: ', fl.shape())\n",
    "        w = dg.identity(np.random.randn(10, 384))\n",
    "        b = dg.identity(np.random.randn(10, 1))\n",
    "        print('created parameters w with shape {} and b with shape {}'.format(w.shape(), b.shape()))\n",
    "        print('w shape:', w.shape())\n",
    "        fc = dg.mat_mul(w, fl)\n",
    "        print('added fully connect layer with shape: {}'.format(fc.shape()))\n",
    "        out = dg.mat_add(fc, b)\n",
    "        print('added bias to give logits output with shape: {}'.format(out.shape()))\n",
    "        loss = dg.softmax_cross(out, y_label)\n",
    "        print('added cross entropy with softmax loss with shape: {}'.format(loss.shape()))\n",
    "        return loss, out, img_in, y_label, [w,b] + conv.op.params()\n",
    "    \n",
    "    def two_conv_layer(self):\n",
    "        print('Creating two conv layer CNN...')\n",
    "        x_entry = x_data.numpy().reshape([batch_size, 28, 28, 1])\n",
    "        y_entry = label2onehot(y_data).reshape([batch_size, num_labels, 1])\n",
    "        print('Input image shape:', x_entry.shape)\n",
    "        print('Y label shape:', y_entry.shape)\n",
    "        print()\n",
    "        img_in = dg.identity(x_entry)\n",
    "        y_label = dg.identity(y_entry)\n",
    "        conv = dg.cnn.conv(img_in, 5, 6)\n",
    "        print('added conv layer with filter size: {}, num_filter: {}, stride: {}, padding: {}, out shape: {}'\\\n",
    "              .format(conv.op.filter_size, conv.op.num_filter, conv.op.stride, conv.op.padding, conv.shape()))\n",
    "        relu = dg.relu(conv)\n",
    "        print('added relu, shape:', relu.shape())\n",
    "        conv2 = dg.cnn.conv(relu, 5, 12)\n",
    "        print('added conv layer with filter size: {}, num_filter: {}, stride: {}, padding: {}, out shape: {}'\\\n",
    "             .format(conv2.op.filter_size, conv2.op.num_filter, conv2.op.stride, conv2.op.padding, conv2.shape()))\n",
    "        relu2 = dg.relu(conv2)\n",
    "        pool = dg.cnn.max_pool(relu2, 5, stride = 3)\n",
    "        print('added pool with filter size: {}, stride: {}, padding: {}, out shape: {}'\\\n",
    "              .format(pool.op.filter_size, pool.op.stride, pool.op.padding, pool.shape()))\n",
    "        fl = dg.reshape(pool, (batch_size, 432, 1))\n",
    "        print('added reshaped layer, the new shape: ', fl.shape())\n",
    "        w = dg.identity(np.random.randn(10, 432))\n",
    "        b = dg.identity(np.random.randn(10, 1))\n",
    "        print('created parameters w with shape {} and b with shape {}'.format(w.shape(), b.shape()))\n",
    "        print('w shape:', w.shape())\n",
    "        fc = dg.mat_mul(w, fl)\n",
    "        print('added fully connect layer with shape: {}'.format(fc.shape()))\n",
    "        out = dg.mat_add(fc, b)\n",
    "        print('added bias to give logits output with shape: {}'.format(out.shape()))\n",
    "        loss = dg.softmax_cross(out, y_label)\n",
    "        print('added cross entropy with softmax loss with shape: {}'.format(loss.shape()))\n",
    "        return loss, out, img_in, y_label, [w,b] + conv.op.params()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating one conv layer CNN...\n",
      "Input image shape: (25, 28, 28, 1)\n",
      "Y label shape: (25, 10, 1)\n",
      "\n",
      "added conv layer with filter size: (5, 5), num_filter: 6, stride: (1, 1), padding: (0, 0), out shape: (25, 24, 24, 6)\n",
      "added relu, shape: (25, 24, 24, 6)\n",
      "added pool with filter size: (3, 3), stride: (3, 3), padding: (0, 0), out shape: (25, 8, 8, 6)\n",
      "added reshaped layer, the new shape:  (25, 384, 1)\n",
      "created parameters w with shape (10, 384) and b with shape (10, 1)\n",
      "w shape: (10, 384)\n",
      "added fully connect layer with shape: (25, 10, 1)\n",
      "added bias to give logits output with shape: (25, 10, 1)\n",
      "added cross entropy with softmax loss with shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "loss, out, x_img, y_label, trainables = net.one_conv_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after training 1 batches with batch size 25: [3.09048429]\n",
      "Accuracy: 0.8\n",
      "Loss after training 101 batches with batch size 25: [1.53012284]\n",
      "Accuracy: 0.92\n",
      "Loss after training 201 batches with batch size 25: [4.26565363]\n",
      "Accuracy: 0.76\n",
      "Loss after training 301 batches with batch size 25: [0.15377387]\n",
      "Accuracy: 0.96\n",
      "Loss after training 401 batches with batch size 25: [2.91129161]\n",
      "Accuracy: 0.8\n",
      "Loss after training 501 batches with batch size 25: [2.3262606]\n",
      "Accuracy: 0.88\n",
      "Loss after training 601 batches with batch size 25: [0.79851772]\n",
      "Accuracy: 0.96\n",
      "Loss after training 701 batches with batch size 25: [0.6354612]\n",
      "Accuracy: 0.92\n",
      "Loss after training 801 batches with batch size 25: [3.00969612]\n",
      "Accuracy: 0.92\n",
      "Loss after training 901 batches with batch size 25: [5.11040749]\n",
      "Accuracy: 0.84\n",
      "Loss after training 1001 batches with batch size 25: [1.19893493]\n",
      "Accuracy: 0.84\n",
      "Loss after training 1101 batches with batch size 25: [2.244793]\n",
      "Accuracy: 0.84\n",
      "Loss after training 1201 batches with batch size 25: [1.47354921]\n",
      "Accuracy: 0.88\n",
      "Loss after training 1301 batches with batch size 25: [2.60093423]\n",
      "Accuracy: 0.8\n",
      "Loss after training 1401 batches with batch size 25: [0.99131269]\n",
      "Accuracy: 0.88\n",
      "Loss after training 1501 batches with batch size 25: [1.90478023]\n",
      "Accuracy: 0.8\n",
      "Loss after training 1601 batches with batch size 25: [2.48357607]\n",
      "Accuracy: 0.72\n",
      "Loss after training 1701 batches with batch size 25: [0.54050249]\n",
      "Accuracy: 0.92\n",
      "Loss after training 1801 batches with batch size 25: [0.58082448]\n",
      "Accuracy: 0.88\n",
      "Loss after training 1901 batches with batch size 25: [0.62883378]\n",
      "Accuracy: 0.88\n",
      "Loss after training 2001 batches with batch size 25: [1.49902219]\n",
      "Accuracy: 0.92\n",
      "Loss after training 2101 batches with batch size 25: [2.14948828]\n",
      "Accuracy: 0.84\n",
      "Loss after training 2201 batches with batch size 25: [0.00992516]\n",
      "Accuracy: 1.0\n",
      "Loss after training 2301 batches with batch size 25: [1.64873379]\n",
      "Accuracy: 0.92\n",
      "Finished training 1 epoches and it cost 1011.779378414154 seconds or 16.86 minutes.\n"
     ]
    }
   ],
   "source": [
    "# finally, train the built CNN\n",
    "lr = 0.0001\n",
    "sgd_optim = dg.optim.SGD(loss, trainables, lr)\n",
    "epoch = 1\n",
    "start = time.time()\n",
    "for e in range(epoch):\n",
    "    train_iter = iter(trainloader)\n",
    "    for i, train_data in enumerate(train_iter):\n",
    "        x_train = train_data[0].numpy().reshape([batch_size, 28, 28, 1])\n",
    "        y_train = label2onehot(train_data[1]).reshape([batch_size, num_labels, 1])\n",
    "        sgd_optim.step({x_img:x_train, y_label:y_train})\n",
    "        if i % 100 == 0:\n",
    "            print('Loss after training {} batches with batch size {}: {}'.format(i + 1, batch_size, loss.data()))\n",
    "            print('Accuracy:', calc_acc(out.data(), y_label.data()))\n",
    "end = time.time()\n",
    "time_peri = end - start\n",
    "print('Finished training {} epoches and it cost {} seconds or {} minutes.'.format(epoch, time_peri, round(time_peri / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
